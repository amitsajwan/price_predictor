# Exploratory Data Analysis (EDA) Agent Prompt

## Objective

Analyze the dataset to understand structure, quality, and patterns. Provide insights to guide downstream tasks like feature engineering and modeling.

You are helping build a model to predict **next day's log return**. Define:

```python
# Log return:
df["Target_return"] = np.log(df["Close"]).shift(-1) - np.log(df["Close"])
```

---

## Input

```json
{initial_data}
```

> These must include a reference to the initial raw data CSV file.

**Hint to PythonTool:** Name the created Python file as `EDA.py`. Pass context as `{initial_data}`.

---

## Data Preparation

* Load the raw dataset.

* Convert `Date` column to datetime format and set it as index (if present).

* Perform necessary preprocessing:

  * Handle missing values (e.g., imputation, dropping)
  * Handle outliers (IQR or z-score)
  * Encode categorical columns (label/one-hot)
  * Drop constant or duplicate columns

* Split the dataset into **train**, **val**, and **test** sets chronologically.

* Save cleaned, combined (X + y) versions as:

  * `eda_cleaned_train_ref.csv`
  * `eda_cleaned_val_ref.csv`
  * `eda_cleaned_test_ref.csv`

---

## EDA Instructions

Perform all steps listed below. **Avoid charts or plots. Return in structured plain text.**

### Structure of the EDA Report

**1. Introduction**

* Brief introduction to the dataset and EDA objective

**2. Data Overview**

* Number of rows and columns
* Data types of all columns
* Unique values per categorical column
* Constant columns (if any)

**3. Missing & Duplicate Values**

* Count and % of missing values per column
* Number of duplicate rows

**4. Univariate Analysis**

* For numeric columns: mean, median, std, min, max
* For categoricals: top categories and counts

**5. Bivariate Analysis**

* Correlation of features with `Target_return`
* Group-wise trends (e.g., by category or time)

**6. Outlier Detection**

* Use IQR or z-score to list features with extreme values

**7. Feature Relationship Analysis**

* Correlation matrix
* Multicollinearity detection

**8. Feature Engineering Suggestions**

* Log, lag, rolling, ratio, interaction features
* Scaling, encoding recommendations
* Use of external packages like `ta`, `pandas-ta`, etc.

**9. Modeling Recommendations**

* Classification vs Regression
* Preprocessing requirements
* Any potential data leakage concerns

---

## Final Output

Return a JSON object with the following keys:

```json
{
  "eda_summary": "High correlation between lag_1 and Target_return. 3 features have >20% missing. No major data leakage detected.",
  "eda_report_ref": "eda_report_2025_06_24.txt",
  "eda_cleaned_train_ref": "eda_cleaned_train_ref.csv",
  "eda_cleaned_val_ref": "eda_cleaned_val_ref.csv",
  "eda_cleaned_test_ref": "eda_cleaned_test_ref.csv",
  "target_col": "Target_return",
  "problem_type": "regression"
}
```

---

## Notes

* `eda_report_ref` must be a self-contained `.txt` file with proper structure, headers, and formatting.
* Do not return a Python file.
* `eda_summary` should be brief — 2-5 lines max.
* All outputs must be verifiable. Ensure the files actually exist.
* You may use tools like `pandas-profiling`, `sweetviz`, or manual code.
* Charts, plots, and images are NOT allowed — return plain text only.

---
