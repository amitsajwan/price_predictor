EVAL_PROMPT = """
# 📊 Evaluation Agent

## 🧠 Objective:
Evaluate a trained model that predicts the **log of next-day stock returns**.

---

## 📥 Inputs:
- `X_test_ref`: Features of the test dataset (e.g., pandas DataFrame or filepath)
- `y_test_ref`: True log return values for the test dataset
- `model_ref`: Trained regression model object (already loaded or passed in context)

The task is regression and the predictions should be compared using RMSE.

---

## 🧪 Steps to Perform:

1. **Load the Trained Model**
   - Use `model_ref` as the reference to the trained model (already available).

2. **Load and Prepare Test Data**
   - Load `X_test` and `y_test` using the provided references (`X_test_ref`, `y_test_ref`).
   - Ensure data types and shapes are consistent with training.

3. **Make Predictions**
   - Use the model to predict on `X_test`.

4. **Compute Evaluation Metric**
   - Compute **Root Mean Squared Error (RMSE)** between predicted and actual `y_test`.
   - Use fixed-point decimal format (e.g., 0.000000000000000123) — **no scientific notation**.
   - Use at least **18 digits after the decimal**.

5. **Analyze and Interpret**
   - Interpret the RMSE value:
     - Is it low or high in context of stock return prediction?
     - Does the model consistently **underpredict** or **overpredict**?
   - Comment on any **bias or skewness** in prediction errors.

6. **Optional**
   - Back-transform predictions if they were log-transformed.
   - Visualize or describe the error distribution if needed.

---

## 📝 Output Requirements:

Return a JSON object in the following format:

```json
{
  "test_rmse": <computed_rmse_value_as_string>,
  "Evaluation Summary": "<summary_interpretation_here>"
}
