# Feature Engineering Agent Prompt

## Objective

Use insights from EDA to generate engineered features for modeling. Apply transformations on cleaned train/val/test splits. Loop through multiple feature set definitions and return modeling-ready references.

---

## Input

```json
{{eda_output}}
```

Expected keys:

* `eda_cleaned_train_ref`
* `eda_cleaned_val_ref`
* `eda_cleaned_test_ref`
* `target_col`

The files include both features and target.

---

## Feature Engineering Steps

1. **Load cleaned train/val/test files** from EDA.

2. **Separate features and target**

   * Extract `y_train`, `y_val`, `y_test` from target column.
   * Store `X_train`, `X_val`, `X_test` as all remaining columns.

3. **Full Feature Engineering on Train**

   * Generate new features:

     * Lag features: `lag_1`, `lag_2`, `lag_3`, etc.
     * Rolling statistics: mean, std, z-score, min, max
     * Technical indicators: RSI, MACD, ATR, Bollinger Bands, etc. (via `ta` or `pandas-ta`)
     * Price ratios: `Close/Open`, `High/Low`, etc.
     * Volatility indicators: rolling std, ATR, Bollinger width
     * Interaction features: cross terms, price \* volume, etc.
   * **Fit any transformers (e.g., scalers, encoders) on X\_train only**
   * Apply transforms to `X_val` and `X_test`

4. **Feature Scaling** (as needed)

   * Use `StandardScaler` or `RobustScaler`
   * Fit only on `X_train`, apply to `X_val`, `X_test`

5. **Store Full Feature Set** (base for all subsets)

   * `engineered_X_train`, `engineered_X_val`, `engineered_X_test`

---

## Subset Loop (Feature Set Variants)

Loop through 10–12 different feature sets:

* All Features
* Top correlated with target
* No highly correlated (drop collinear)
* Lag-only features
* Rolling-only features
* TA indicators only
* Low missing features only
* High variance features
* Interaction-only
* SHAP or importance-based top N (if available)

### For each subset:

1. Select columns from full feature set
2. Save subset files:

   * `x_train_ref`, `x_val_ref`, `x_test_ref`
   * `y_train_ref`, `y_val_ref`, `y_test_ref`
3. Append config:

```json
{
  "name": "top_corr_features",
  "x_train_ref": "x_train_top_corr.csv",
  "x_val_ref": "x_val_top_corr.csv",
  "x_test_ref": "x_test_top_corr.csv",
  "y_train_ref": "y_train.csv",
  "y_val_ref": "y_val.csv",
  "y_test_ref": "y_test.csv",
  "model": "RandomForestRegressor",
  "parameters": {{}}
}
```

4. Only append if all referenced files exist.

---

## Final Output

Return a JSON object:

```json
{
  "modeling-run-configs": [
    { subset_config_1 },
    { subset_config_2 },
    ...
  ]
}
```

---

## Notes

* Use `ta`, `pandas-ta`, `tsfresh`, `sklearn`, `category_encoders`, etc.
* Do not re-split the data.
* Always save files inside loop.
* Ensure clean handling of time-based structure.
* Avoid leakage from future or target-aligned features.
* Do not return any plots or notebooks — just plain structured JSON.
