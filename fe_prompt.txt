# Feature Engineering and Model Selection Agent Prompt

## Objective:

Engineer feature sets from the datasets based on **EDA insights**.
Select suitable machine learning models for each feature set and prepare model configurations.
This will be used in modeling to predict the **next day's log return**.

---

## Context:

**EDA Report:** Use insights from the EDA summary and report to inform feature engineering and model selection.

### Full EDA Report:

**EDA Summary:**
{eda\_summary}

```
{eda_report_text}
```

---

## Data Files:

**Format:** JSON

```json
 data_files_ref = {initial_data} 
```

> These must include combined split files (X + y in one DataFrame):
>
> * `train.csv`
> * `val.csv`
> * `test.csv`
>
> Target column is `Target_return`.

> ⚠️ **Splitting into train/val/test should be done during EDA.** Feature Engineering Agent should not perform splitting.

---

## Instructions:

### Step 1: Analyze EDA Report and Identify Features

* Review EDA findings to identify key variables, insights, and recommended transformations.
* Select top features for engineering based on the summary.
* Plan appropriate transformations and feature combinations.

---

### Step 2: Data Preparation

* Load the split files: `train.csv`, `val.csv`, `test.csv`
* Convert the `Date` column to datetime format and set as index (if applicable)
* Perform all preprocessing (e.g., NA handling, outlier removal, feature generation) on full DataFrame
* **Only after all transformations**, split each into:

  * `X` = features (drop `Target_return`)
  * `y` = target (`Target_return`)
* This ensures `X` and `y` remain aligned after row drops or filtering

---

### Step 3: Develop Feature Sets

* Create \~10 distinct feature sets based on strategies identified in the EDA.
* Include combinations of raw, lag, rolling, interaction, technical, and categorical features.

---

### Step 4: Perform Feature Engineering

* Implement feature engineering **on `train` only** (for fitting transformers)
* Apply fitted transformers (e.g., scalers, encoders) **to `val` and `test`** without re-fitting
* If using lag features or time-based windows, use **t-1** and earlier data only
* Ensure no target leakage during feature creation
* After feature creation, check for NaNs:

  * Drop rows (only if small in number)
  * Or fill using median/mean/constant (based on `train` only)
  * Or use forward/backward fill if time series
  * Apply same strategy to `val` and `test`

---

### Step 5: Save Feature Set Files

For each feature set, save the processed files:

* `feature_set_name_train.csv` → features (X)
* `feature_set_name_train_y.csv` → target (y)
* `feature_set_name_val.csv` → features (X)
* `feature_set_name_val_y.csv` → target (y)
* `feature_set_name_test.csv` → features (X)
* `feature_set_name_test_y.csv` → target (y)

Each `*_y.csv` should contain only the `Target_return` column

---

### Step 5.1: For Each Feature Set

* Subset columns based on selected features only
* Handle missing values, remove outliers (if required)
* Ensure alignment between feature rows and target rows
* Save cleaned files separately

---

### Step 6: Select Suitable Models

* Choose models best suited for each feature set (based on EDA & feature characteristics)
* Define model type and parameter configuration per feature set

---

### Step 7: Prepare Modeling Run Configurations

Return a JSON list of modeling configurations for each (feature set, model) combination
Each config should include:

* Feature set file references (train/val/test) for `X`
* Corresponding file references for `y`
* Model type
* Model parameters
* Justification (optional but helpful)

---

## Final Output:

Return only a valid JSON object:

```json
{
  "modeling-run-configs": [
    {
      "name": "high_corr_rf",
      "description": "Using high correlation features with RandomForest",
      "train_ref": "high_corr_train.csv",
      "train_y_ref": "high_corr_train_y.csv",
      "val_ref": "high_corr_val.csv",
      "val_y_ref": "high_corr_val_y.csv",
      "test_ref": "high_corr_test.csv",
      "test_y_ref": "high_corr_test_y.csv",
      "model": "RandomForest",
      "parameters": {
        "n_estimators": 100,
        "max_depth": 10,
        "random_state": 42
      }
    }
  ]
}
```

> ✅ Ensure JSON is valid using `json.loads`
> ❌ Do not include commentary, extra text, or models without valid features

---

## Notes:

* Fit transformers only on `train`, apply to `val` and `test`
* Always split into `X` and `y` after preprocessing to ensure alignment
* If engineered features contain NaNs, handle them consistently using train-only strategy
* File names must be consistent and clean
* Ensure repeatable and aligned outputs
