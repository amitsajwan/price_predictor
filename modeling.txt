# Modeling Agent Prompt

## Objective:

Train and evaluate regression models using the **provided feature sets and configurations**.
The goal is to predict the next day's log return (`Target_return`) with the best possible RMSE.

---

## Input:

### Modeling Config File

Path to a JSON file (e.g., `FeatureEngineering_List.json`) containing a list of modeling configurations.
Each configuration is a JSON object with keys:

* `name`: Name of the feature set/model configuration
* `description`: Optional explanation
* `train_ref`: Path to engineered train X
* `train_y_ref`: Path to corresponding train y
* `val_ref`: Path to engineered val X
* `val_y_ref`: Path to corresponding val y
* `test_ref`: Path to engineered test X
* `test_y_ref`: Path to corresponding test y
* `model_name`: Model type (e.g., `RandomForestRegressor`)
* `parameters`: Hyperparameters

> All files should be preprocessed and clean — no further transformation needed.

---

## Instructions:

### Step 1: Load Config File

* Load the JSON file containing all model run configurations
* Verify the JSON is valid and parse it into a list of config objects

---

### Step 2: Loop Through Configurations

For each config in the list, perform the following substeps:

#### 2.1 Load Data

* Load `train_ref`, `train_y_ref`, `val_ref`, `val_y_ref`, `test_ref`, `test_y_ref`
* Validate that the number of rows in X and y files match for each split
* Ensure the `Target_return` column is present in all y files

#### 2.2 Train Model

* Initialize the specified model (e.g., `RandomForestRegressor`) using the given `parameters`
* Fit the model on `train_ref` and `train_y_ref`

#### 2.3 Validate Model

* Predict on `val_ref`
* Compute RMSE between predictions and `val_y_ref`

#### 2.4 Evaluate on Test Set

* Predict on `test_ref`
* Compute RMSE between predictions and `test_y_ref`

#### 2.5 Save Model

* Save the trained model using `joblib` to disk using a filename based on the `name` field (e.g., `model_ref = name + '.pkl'`)

#### 2.6 Prepare Output Entry

Append the following to the result list:

```json
{
  "name": "...",
  "description": "...",
  "model_ref": "...",
  "train_rmse": ...,
  "val_rmse": ...,
  "test_rmse": ...,
  "train_ref": "...",
  "train_y_ref": "...",
  "val_ref": "...",
  "val_y_ref": "...",
  "test_ref": "...",
  "test_y_ref": "..."
}
```

---

### Step 3: Retry Logic

* If any configuration fails (e.g., due to file error or model crash), retry up to 6 times
* Log the failure after max retries and skip that config

---

## Final Output:

Return a list of completed configurations with model paths and RMSEs:

```json
[
  {
    "name": "high_corr_rf",
    "description": "RandomForest using high correlation features",
    "model_ref": "high_corr_rf.pkl",
    "train_rmse": 0.0123,
    "val_rmse": 0.0134,
    "test_rmse": 0.0148,
    "train_ref": "high_corr_train.csv",
    "train_y_ref": "high_corr_train_y.csv",
    "val_ref": "high_corr_val.csv",
    "val_y_ref": "high_corr_val_y.csv",
    "test_ref": "high_corr_test.csv",
    "test_y_ref": "high_corr_test_y.csv"
  }
]
```

> ✅ Ensure JSON is valid
> ❌ No logs or debug output in final result

---

## Notes:

* Use `Target_return` for all y values
* Do not modify the input files
* Return only the valid modeling results
* All file names must match those in config
* Use `sqrt(mean_squared_error(...))` to compute RMSE
* Save model using `joblib.dump(model, model_ref)`
